[
  {
    "objectID": "cdcdata-exercis/cdcdata-exercise.html",
    "href": "cdcdata-exercis/cdcdata-exercise.html",
    "title": "CDC Provisional Percent of Deaths for COVID-19, Influenza, and RSV by Select Characteristics Data Processing Exercise",
    "section": "",
    "text": "This dataset contains the provisional percent of total deaths by week for COVID-19, Influenza, and Respiratory Syncytial Virus for deaths occurring among residents in the United States, by sex, age group, and race and Hispanic origin.This dataset was taken from the CDC website and can be found at the following link.\nLink: https://data.cdc.gov/National-Center-for-Health-Statistics/Provisional-Percent-of-Deaths-for-COVID-19-Influen/53g5-jf7x/about_data\nThe clean dataset has 7 columns/variables:\n* year: a numerical value denoting a year between 2018-2025\n* weekending_date: date of the weekend of the week the data was recorded for\n* demographic_type: demographic type has been processes to only include Age Group\n* demographic_values: text denoting what age group that data is for (0-17 years, 18-64 years, 65+ years)\n* pathogen: RSV, COVID-19, Influenza, or Combined\n* deaths: number of deaths involving pathogen for that week for that age group\n* total_deaths: deaths from all causes of death"
  },
  {
    "objectID": "cdcdata-exercis/cdcdata-exercise.html#synthetic-data-alex",
    "href": "cdcdata-exercis/cdcdata-exercise.html#synthetic-data-alex",
    "title": "CDC Provisional Percent of Deaths for COVID-19, Influenza, and RSV by Select Characteristics Data Processing Exercise",
    "section": "Synthetic Data (Alex)",
    "text": "Synthetic Data (Alex)\nThis section contributed by Alex Tejada-Strop.\nI generated a synthetic dataset with the same structure as the cleaned dataset (data_clean). Categorical variables were sampled using the same proportions as the original data, and numeric death counts were simulated using a Poisson-based approach based on the original averages. The synthetic data should look similar overall but will not match exactly because it is randomly generated.\n\n# AI was used for guidance in structuring synthetic data generation and troubleshooting minor coding errors.\n\nset.seed(123)\n\norig &lt;- data_clean\nn &lt;- nrow(orig)\n\n# Helper function to sample categorical variables\nsample_like &lt;- function(x, size) {\n  probs &lt;- prop.table(table(x))\n  sample(names(probs), size = size, replace = TRUE, prob = as.numeric(probs))\n}\n\n# Helper function for count-style numeric variables\nmake_counts &lt;- function(x, size) {\n  mu &lt;- mean(x, na.rm = TRUE)\n  mu &lt;- ifelse(is.na(mu) || mu &lt; 0.1, 1, mu)\n  rpois(size, lambda = mu)\n}\n\nsyn &lt;- tibble(\n  year = sample_like(orig$year, n),\n  weekending_date = sample(orig$weekending_date, n, replace = TRUE),\n  demographic_type = sample_like(orig$demographic_type, n),\n  demographic_values = sample_like(orig$demographic_values, n),\n  pathogen = sample_like(orig$pathogen, n),\n  deaths = make_counts(orig$deaths, n),\n  total_deaths = make_counts(orig$total_deaths, n)\n) %&gt;%\n  mutate(total_deaths = pmax(total_deaths, deaths))\n\nglimpse(syn)\n\nRows: 5,052\nColumns: 7\n$ year               &lt;chr&gt; \"2023\", \"2018\", \"2022\", \"2021\", \"2021\", \"2020\", \"20…\n$ weekending_date    &lt;date&gt; 2022-10-08, 2023-06-03, 2020-11-07, 2018-10-13, 20…\n$ demographic_type   &lt;chr&gt; \"Age Group\", \"Age Group\", \"Age Group\", \"Age Group\",…\n$ demographic_values &lt;chr&gt; \"18-64 years\", \"65+ years\", \"0-17 years\", \"65+ year…\n$ pathogen           &lt;chr&gt; \"RSV\", \"COVID-19\", \"Combined\", \"Influenza\", \"Combin…\n$ deaths             &lt;int&gt; 518, 510, 543, 531, 509, 513, 514, 484, 550, 501, 5…\n$ total_deaths       &lt;int&gt; 20145, 19942, 19998, 19987, 19815, 20058, 20179, 20…\n\n\n\n# --- Compare Original vs Synthetic ---\n\n# Numeric comparison\norig %&gt;%\n  summarise(\n    mean_deaths = mean(deaths, na.rm = TRUE),\n    sd_deaths = sd(deaths, na.rm = TRUE),\n    mean_total = mean(total_deaths, na.rm = TRUE),\n    sd_total = sd(total_deaths, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 4\n  mean_deaths sd_deaths mean_total sd_total\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1        521.     1835.     19976.   18684.\n\nsyn %&gt;%\n  summarise(\n    mean_deaths = mean(deaths, na.rm = TRUE),\n    sd_deaths = sd(deaths, na.rm = TRUE),\n    mean_total = mean(total_deaths, na.rm = TRUE),\n    sd_total = sd(total_deaths, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 4\n  mean_deaths sd_deaths mean_total sd_total\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1        521.      22.7     19978.     140.\n\n# Pathogen proportions\norig %&gt;% count(pathogen) %&gt;% mutate(pct = n / sum(n))\n\n# A tibble: 4 × 3\n  pathogen      n   pct\n  &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt;\n1 COVID-19   1263  0.25\n2 Combined   1263  0.25\n3 Influenza  1263  0.25\n4 RSV        1263  0.25\n\nsyn %&gt;% count(pathogen) %&gt;% mutate(pct = n / sum(n))\n\n# A tibble: 4 × 3\n  pathogen      n   pct\n  &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt;\n1 COVID-19   1275 0.252\n2 Combined   1285 0.254\n3 Influenza  1285 0.254\n4 RSV        1207 0.239\n\n\n\n# --- Synthetic Weekly Deaths by Pathogen ---\n\nsyn %&gt;%\n  filter(pathogen != \"Combined\") %&gt;%\n  group_by(weekending_date, pathogen) %&gt;%\n  summarise(total_deaths = sum(deaths), .groups = \"drop\") %&gt;%\n  ggplot(aes(x = weekending_date, y = total_deaths, color = pathogen)) +\n  geom_line(linewidth = 0.8) +\n  theme_minimal() +\n  labs(\n    title = \"Synthetic Weekly Deaths Over Time by Pathogen\",\n    x = \"Week Ending Date\",\n    y = \"Total Deaths\"\n  )"
  },
  {
    "objectID": "starter-analysis-exercise/starter-analysis-exercise.html",
    "href": "starter-analysis-exercise/starter-analysis-exercise.html",
    "title": "Data Analysis Introduction Exercise",
    "section": "",
    "text": "Gathering Data\n# load dslabs package\nlibrary(\"dslabs\")\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n#takes gapminder dataset and creates a new dataframe that only takes the countries that have \"Africa\" in the continent column\nafricadata &lt;- gapminder[gapminder$continent == \"Africa\", ]\n\n#creates a new dataframe and adds the columns \"infant_mortality\" and \"life_expectancy\" from africadata\nafrica_infant_mortality &lt;- africadata[, c(\"infant_mortality\", \"life_expectancy\")]\n\n#creates a new dataframe and adds the columns \"population\" and \"life_expectancy\" from africadata\nafrica_pop &lt;- africadata[, c(\"population\", \"life_expectancy\")]\nPlotting\n#Plotting life expectancy as a function of infant mortality\n#using the plot function to make the plot and assigning it to a variable named \"plot1\"\nplot1 &lt;- plot( \n  \n  #takes the infant_mortality column from africa_infant_mortality and makes it the x-axis values\n  africa_infant_mortality$infant_mortality, \n  \n  #takes the life expactancy column from africa_infant_mortality and makes it the y-axis values  \n  africa_infant_mortality$life_expectancy, \n    \n  xlab = \"Life Expectancy\", #labels the x-axis \"Life Expectancy\"\n  ylab = \"Infant Mortality\", #labels the y-axis \"Infant Mortality\"\n  \n  #titles the whole plot \"Infant Mortality vs Life Expectancy in Africa\"\n  main = \"Infant Mortality vs Life Expectancy in Africa\" \n)\n\n\n\n\n\n\n\n#Plotting life expectancy as a function of population\n#using the plot function to make the plot and assigning it to a variable named \"plot2\"\nplot2 &lt;- plot( \n\n  #takes the population column from africa_pop and makes it the x-axis values\n  africa_pop$population, \n\n  #takes the life expactancy column from africa_pop and makes it the y-axis values\n  africa_pop$life_expectancy, \n\n  xlab = \"Life Expectancy\", #labels the x-axis \"Life Expectancy\"\n  ylab = \"Population\", #labels the y-axis \"Population\"\n\n  #titles the whole plot \"Population vs Life Expectancy in Africa\"\n  main = \"Population vs Life Expectancy in Africa\",\n    \n  log = \"x\" #sets the scale of the x-axis to be logarithmic\n)\nYou should also see a positive correlation between population size and life expectancy. In both plots, especially the second one, you will see ‘streaks’ of data that seem to go together. Can you figure out what is going on here?\nThe “streaks” in the plots likely represent individual countries observed across multiple years. Because africadata contains statistics for infant mortality and population for the same countries across different years, multiple observations from each country appear in the plots. Since these values typically change gradually over time within a country, the data points remain close together, forming visible “streaks.”\nMore Data Processing\n#figures out which years have missing data for infant mortality\ntapply(africadata$infant_mortality, africadata$year, function(x) sum(is.na(x)))\n\n1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 \n  10   17   16   16   15   14   13   11   11    7    5    6    6    6    5    5 \n1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 \n   3    3    2    2    1    1    0    0    0    0    0    0    0    0    0    0 \n1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 \n   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n2008 2009 2010 2011 2012 2013 2014 2015 2016 \n   0    0    0    0    0    0    0    0   51 \n\n#the tapply function applies a funciton to a set vectors\n#tapply is applying the function sum(is.na(x)) to the groups africadata$infant_mortality and africadata$year\n#the sum() function takes the sum/total of a group\n#the is.na() function checks each value in a dataframe/group is NA or not\n#so sum(is.na(x) returns the total amount of NA values in each year\n\n#Creates a new object by extracting only the data for the year 2000 from the africadata object\nafrica_2000 &lt;- africadata[africadata$year == \"2000\",]\nMore Plotting\n#Plotting life expectancy as a function of infant mortality for year 2000\n#using the plot function to make the plot and assigning it to a variable named \"plot3\"\nplot3 &lt;- plot( \n\n  #takes the infant_mortality column from africa_2000 and makes it the x-axis values\n  africa_2000$infant_mortality,\n\n  #takes the life expactancy column from africa_2000 and makes it the y-axis values\n  africa_2000$life_expectancy,\n    \n  xlab = \"Life Expectancy\", #labels the x-axis \"Life Expectancy\"\n  ylab = \"Infant Mortality\", #labels the y-axis \"Infant Mortality\"\n\n  #titles the whole plot \"Infant Mortality vs Life Expectancy in Africa in 2000\"\n  main = \"Infant Mortality vs Life Expectancy in Africa in 2000\"\n)\n\n\n\n\n\n\n\n#Plotting life expectancy as a function of population\n#using the plot function to make the plot and assigning it to a variable named \"plot4\"\nplot4 &lt;- plot( \n\n  #takes the population column from africa_2000 and makes it the x-axis values \n  africa_2000$population, \n\n  #takes the life expactancy column from africa_2000 and makes it the y-axis values\n  africa_2000$life_expectancy, \n    \n  xlab = \"Life Expectancy\", #labels the x-axis \"Life Expectancy\"\n  ylab = \"Population\", #labels the y-axis \"Population\"\n\n  #titles the whole plot \"Population vs Life Expectancy in Africa in 2000\"\n  main = \"Population vs Life Expectancy in Africa in 2000\", \n    \n  log = \"x\" #sets the scale of the x-axis to be logarithmic\n)\nSimple Model Fits\n# fit1 models life expectancy as a function of infant mortality for African countries in 2000.\n#the lm() function is used to fit linear models\nfit1 &lt;- lm(life_expectancy ~ infant_mortality, data = africa_2000)\nsummary(fit1) #prints results of fir1\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = africa_2000)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      71.29331    2.42611  29.386  &lt; 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\nThe relationship between life expectancy and infant mortality are highly significant (p-value: 2.826e-08) and strongly negatively correlated. Based on the slope, each additional infant death per 1,000 live births is associated with a decrease of approximately 0.19 years in life expectancy. When infant mortality is theoretically zero, predicted life expectancy is about 71.3 years. R squared = 0.47 means about 47% of the variability in life expectancy is explained by infant mortality.\n# fit2 models life expectancy as a function of population for African countries in 2000.\nfit2 &lt;- lm(life_expectancy ~ population, data = africa_2000)\nsummary(fit2) #prints results of fir1\n\n\nCall:\nlm(formula = life_expectancy ~ population, data = africa_2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.429  -4.602  -2.568   3.800  18.802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.593e+01  1.468e+00  38.097   &lt;2e-16 ***\npopulation  2.756e-08  5.459e-08   0.505    0.616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.524 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159\nUnlike infant mortality, population size does not appear to have a meaningful effect on life expectancy (p-value: 0.6159). R-squares = 0.005 means only 0.05% of the variation in life expectancy is explained by population."
  },
  {
    "objectID": "starter-analysis-exercise/starter-analysis-exercise.html#this-section-contributed-by-nalany-richardson",
    "href": "starter-analysis-exercise/starter-analysis-exercise.html#this-section-contributed-by-nalany-richardson",
    "title": "Data Analysis Introduction Exercise",
    "section": "This section contributed by Nalany Richardson",
    "text": "This section contributed by Nalany Richardson\nI chose ml-latest-small dataset from dslabs to see how movies and their IMBD ratings were related.\n\n# Set up packages for data and upload excel files if needed \nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tibble' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.4.3\n\n\n\n# Open excel files from project folder (ml-latest-small is the original name from the dslabs repository). \nmovies  &lt;- read_excel(\"../ml-latest-small/movies.xlsx\")\n\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n\nratings &lt;- read_excel(\"../ml-latest-small/ratings.xlsx\")\ntags &lt;- read_excel(\"../ml-latest-small/tags.xlsx\")\n\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n\n\n\n# Explore the data with str and create summary of data files\nstr(movies)\n\ntibble [9,743 × 3] (S3: tbl_df/tbl/data.frame)\n $ movies: chr [1:9743] \"movieId\" \"1\" \"2\" \"3\" ...\n $ ...2  : chr [1:9743] \"title\" \"Toy Story (1995)\" \"Jumanji (1995)\" \"Grumpier Old Men (1995)\" ...\n $ ...3  : chr [1:9743] \"genres\" \"Adventure|Animation|Children|Comedy|Fantasy\" \"Adventure|Children|Fantasy\" \"Comedy|Romance\" ...\n\nstr(ratings)\n\ntibble [100,836 × 4] (S3: tbl_df/tbl/data.frame)\n $ userId   : num [1:100836] 1 1 1 1 1 1 1 1 1 1 ...\n $ movieId  : num [1:100836] 1 3 6 47 50 70 101 110 151 157 ...\n $ rating   : num [1:100836] 4 4 4 5 5 3 5 4 5 5 ...\n $ timestamp: num [1:100836] 9.65e+08 9.65e+08 9.65e+08 9.65e+08 9.65e+08 ...\n\nstr(tags)\n\ntibble [3,684 × 4] (S3: tbl_df/tbl/data.frame)\n $ tags: chr [1:3684] \"userId\" \"2\" \"2\" \"2\" ...\n $ ...2: chr [1:3684] \"movieId\" \"60756\" \"60756\" \"60756\" ...\n $ ...3: chr [1:3684] \"tag\" \"funny\" \"Highly quotable\" \"will ferrell\" ...\n $ ...4: chr [1:3684] \"timestamp\" \"1445714994\" \"1445714996\" \"1445714992\" ...\n\nsummary(movies)\n\n    movies              ...2               ...3          \n Length:9743        Length:9743        Length:9743       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n\nsummary(ratings)\n\n     userId         movieId           rating        timestamp        \n Min.   :  1.0   Min.   :     1   Min.   :0.500   Min.   :8.281e+08  \n 1st Qu.:177.0   1st Qu.:  1199   1st Qu.:3.000   1st Qu.:1.019e+09  \n Median :325.0   Median :  2991   Median :3.500   Median :1.186e+09  \n Mean   :326.1   Mean   : 19435   Mean   :3.502   Mean   :1.206e+09  \n 3rd Qu.:477.0   3rd Qu.:  8122   3rd Qu.:4.000   3rd Qu.:1.436e+09  \n Max.   :610.0   Max.   :193609   Max.   :5.000   Max.   :1.538e+09  \n\nsummary(tags)\n\n     tags               ...2               ...3               ...4          \n Length:3684        Length:3684        Length:3684        Length:3684       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n\n# make movies summary from ratings\nmovie_summary &lt;- ratings %&gt;%\n  filter(!is.na(rating)) %&gt;%\n  group_by(movieId) %&gt;%\n  summarise(\n    avg_rating = mean(rating),\n    n_ratings  = n(),\n    .groups = \"drop\"\n  )\n\n\n# Converted from .csv to .xlsx which created spaces in column. Run trimws to fix.\nnames(movies)  &lt;- trimws(names(movies))\nnames(ratings) &lt;- trimws(names(ratings))\n# Remove any missing ratings\nratings_clean &lt;- ratings %&gt;%\n  filter(!is.na(rating))\n# Process and join movie and rating data\nratings_clean &lt;- ratings %&gt;%\n  filter(!is.na(rating))\n# Reinspect cleaned data\nstr(ratings_clean)\n\ntibble [100,836 × 4] (S3: tbl_df/tbl/data.frame)\n $ userId   : num [1:100836] 1 1 1 1 1 1 1 1 1 1 ...\n $ movieId  : num [1:100836] 1 3 6 47 50 70 101 110 151 157 ...\n $ rating   : num [1:100836] 4 4 4 5 5 3 5 4 5 5 ...\n $ timestamp: num [1:100836] 9.65e+08 9.65e+08 9.65e+08 9.65e+08 9.65e+08 ...\n\nsummary(ratings_clean$rating)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.500   3.000   3.500   3.502   4.000   5.000 \n\n\n\n# Plot average rating vs number of ratings\nggplot(movie_summary, aes(x = n_ratings, y = avg_rating)) +\n  geom_point(alpha = 0.4) +\n  scale_x_log10() +\n  labs(\n    title = \"Average rating vs number of ratings (by movieId)\",\n    x = \"Number of ratings (log scale)\",\n    y = \"Average rating\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nInterpretation\nMovies were summarized using average user ratings and the total number of ratings/movie. This plot aims to show the relationship between ‘popularity’ (number of ratings) and level of rating (1- worst and 5- best rating). As the number of reviews goes up, it appears that the average rating also increases.\n\n# Now we'll make a simple fit model. But first, we need to fix column names in 'tags' and make sure the movieId types match (some data points are misaligned).\nnames(tags)[1:4] &lt;- c(\"userId\", \"movieId\", \"tag\", \"timestamp\")\ntags$movieId &lt;- as.numeric(tags$movieId)\n\nWarning: NAs introduced by coercion\n\n# Create movie average rating\nmovie_summary &lt;- ratings %&gt;%\n  filter(!is.na(rating)) %&gt;%\n  group_by(movieId) %&gt;%\n  summarise(avg_rating = mean(rating), .groups = \"drop\")\n# Let's do 'funny' tagged movies and see what happens...\ntest_tag &lt;- \"funny\"\n# Don't forget to make an indicator. AI was used to figure out this step and deploy the code.\ntag_indicator &lt;- tags %&gt;%\n  filter(tag == test_tag) %&gt;%\n  distinct(movieId) %&gt;%\n  mutate(has_tag = 1)\n# NOW we can combine the data and create fit model\n# Do movies tagged as 'funny' have different average ratings than movies without the tag? AI was used to discover how to use left_join\ntag_df &lt;- movie_summary %&gt;%\n  left_join(tag_indicator, by = \"movieId\") %&gt;%\n  mutate(has_tag = ifelse(is.na(has_tag), 0, has_tag))\n\nfit_tag &lt;- lm(avg_rating ~ has_tag, data = tag_df)\nsummary(fit_tag)\n\n\nCall:\nlm(formula = avg_rating ~ has_tag, data = tag_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7615 -0.4623  0.1551  0.6470  1.7385 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3.261530   0.008829 369.409   &lt;2e-16 ***\nhas_tag     0.425037   0.189988   2.237   0.0253 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8697 on 9722 degrees of freedom\nMultiple R-squared:  0.0005145, Adjusted R-squared:  0.0004117 \nF-statistic: 5.005 on 1 and 9722 DF,  p-value: 0.0253"
  },
  {
    "objectID": "starter-analysis-exercise/starter-analysis-exercise.html#interpretation-of-fit-model",
    "href": "starter-analysis-exercise/starter-analysis-exercise.html#interpretation-of-fit-model",
    "title": "Data Analysis Introduction Exercise",
    "section": "Interpretation of fit model",
    "text": "Interpretation of fit model\nA simple linear regression was used to examine whether the presence of the tag “funny” (ascribed by users) was associated with low, average, or higher movie ratings than non-‘funny’ movies.. Movies tagged as “funny” had significantly higher average ratings compared to movies without this tag (β = 0.43, p = 0.0253). Funny movies average a rating of 3.69 compared to their unfunny counterparts at 3.26. While the model only explains a small proportion of total variation in ratings (R2 = 0.0005), there does appear to be a significant relationship here. This was a fun analysis, and I was surprised that funnier movies actually had a positive impact on user rating."
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Synthetic Data Exercise",
    "section": "",
    "text": "Introduction and Data\nThis synthetic data generation is taken from the notes while reducing the number of variables, so I can understand how to generate and explore the data better. This synthetic dataset includes basic patient-level variables such as age, gender, treatment group, and blood pressure. I wanted to explore the relationship these variables had with each other, especially how they affect blood pressure. Blood pressure was not intentially associated with any other variables and was generated randomly.\n\n# make sure the packages are installed\n# Load required packages\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ggplot2)\n\n# Set a seed for reproducibility\nset.seed(123)\n# Define the number of observations (patients) to generate\nn_patients &lt;- 100\n\nsyn_dat &lt;- data.frame(\n  PatientID = numeric(n_patients),\n  Age = numeric(n_patients),\n  Gender = character(n_patients),\n  TreatmentGroup = character(n_patients),\n    BloodPressure = numeric(n_patients)\n)\n\n#Patient ID\nsyn_dat$PatientID &lt;- 1:n_patients\n\n#Age (numeric variable)\nsyn_dat$Age &lt;- round(rnorm(n_patients, mean = 45, sd = 10), 1)\n\n#Gender (categorical variable)\nsyn_dat$Gender &lt;- purrr::map_chr(sample(c(\"Male\", \"Female\"), n_patients, replace = TRUE), as.character)\n\n#Treatment Group (categorical variable)\nsyn_dat$TreatmentGroup &lt;- purrr::map_chr(sample(c(\"A\", \"B\", \"Placebo\"), n_patients, replace = TRUE), as.character)\n\n#Blood Pressure (numeric variable)\nsyn_dat$BloodPressure &lt;- round(runif(n_patients, min = 90, max = 160), 1)\n\nhead(syn_dat)\n\n  PatientID  Age Gender TreatmentGroup BloodPressure\n1         1 39.4 Female              B         135.1\n2         2 42.7 Female              B         131.7\n3         3 60.6 Female              A         112.5\n4         4 45.7   Male              B         152.4\n5         5 46.3 Female              A         133.8\n6         6 62.2 Female              A         111.2\n\n\n\n\nPlotting\nThese plots explore how blood pressure varies across treatment groups, gender, and age in the synthetic dataset. Boxplots are used to compare the distribution of blood pressure by treatment group and gender, while a scatterplot with a fitted regression line illustrates the relationship between age and blood pressure.\n\n# ggplot2 boxplot for blood pressure by treatment group\nggplot(syn_dat, aes(x = TreatmentGroup, y = BloodPressure)) +\n  geom_boxplot() +\n  labs(x = \"Treatment Group\", y = \"BloodPressure\") +\n  theme_bw()\n\n\n\n\n\n\n\n# ggplot2 boxplot for blood pressure by gender\nggplot(syn_dat, aes(x = Gender, y = BloodPressure)) +\n  geom_boxplot() +\n  labs(x = \"Gender\", y = \"BloodPressure\") +\n  theme_bw()\n\n\n\n\n\n\n\n#ggplot2 scatterplot for blood pressure by age\nggplot(syn_dat, aes(x = Age, y = BloodPressure)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Age vs Blood Pressure\",\n    x = \"Age\",\n    y = \"Blood Pressure\"\n  ) +\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nlm_bp &lt;- lm(BloodPressure ~ Age + Gender + TreatmentGroup, data = syn_dat)\nsummary(lm_bp)\n\n\nCall:\nlm(formula = BloodPressure ~ Age + Gender + TreatmentGroup, data = syn_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.470 -16.416  -2.604  15.987  39.595 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           121.45551   11.79335  10.299   &lt;2e-16 ***\nAge                     0.08979    0.22940   0.391    0.696    \nGenderMale             -1.57000    4.11804  -0.381    0.704    \nTreatmentGroupB        -1.56911    4.86859  -0.322    0.748    \nTreatmentGroupPlacebo  -3.40184    5.06002  -0.672    0.503    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.29 on 95 degrees of freedom\nMultiple R-squared:  0.009949,  Adjusted R-squared:  -0.03174 \nF-statistic: 0.2387 on 4 and 95 DF,  p-value: 0.9158\n\nglm_bp &lt;- lm(BloodPressure ~ Age + Gender + TreatmentGroup, data = syn_dat)\nsummary(lm_bp)\n\n\nCall:\nlm(formula = BloodPressure ~ Age + Gender + TreatmentGroup, data = syn_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.470 -16.416  -2.604  15.987  39.595 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           121.45551   11.79335  10.299   &lt;2e-16 ***\nAge                     0.08979    0.22940   0.391    0.696    \nGenderMale             -1.57000    4.11804  -0.381    0.704    \nTreatmentGroupB        -1.56911    4.86859  -0.322    0.748    \nTreatmentGroupPlacebo  -3.40184    5.06002  -0.672    0.503    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.29 on 95 degrees of freedom\nMultiple R-squared:  0.009949,  Adjusted R-squared:  -0.03174 \nF-statistic: 0.2387 on 4 and 95 DF,  p-value: 0.9158\n\n\n\n\nAdditional Dataset Generation\nI decided to try to generate my own completely separate dataset based on how the previous dataset was generated. This new synthetic dataset represents 250 students and includes variables such as age, gender, sleep hours, study hours, and exam scores. Exam scores were generated to increase with study hours and to vary nonlinearly with sleep hours, reflecting optimal performance around 7–8 hours of sleep.\n\nset.seed(123)\n\n# Number of students\nn_students &lt;- 250\n\n# Generate synthetic data\nsyn_students &lt;- data.frame(\n    studentID = numeric(n_students),\n    Age = numeric(n_students),\n    Gender = character(n_students),\n    SleepHours = numeric(n_students),\n    StudyHours = numeric(n_students),\n    ExamScore = numeric(n_students)\n)\n#Student ID\nsyn_students$studentID &lt;- 1:n_students\n\n#Age (numeric variable)\nsyn_students$Age &lt;- round(rnorm(n_students, mean = 20, sd = 3), 1)\n\n#Gender (categorical variable)\nsyn_students$Gender &lt;- purrr::map_chr(sample(c(\"Male\", \"Female\"), n_students, replace = TRUE), as.character)\n\n#Sleep Hours (numeric variable)\nsyn_students$SleepHours &lt;- round(rnorm(n_students, mean = 7, sd = 1.2), 1)\n\n#Study Hours (numeric variable)\nsyn_students$StudyHours &lt;- round(rnorm(n_students, mean = 10, sd = 4), 1)\n\n#Exam Scores (numeric variable) #AI was used to help generate the Exam Score Dependencies\nsyn_students$ExamScore &lt;- round(50 + 2.5 * syn_students$StudyHours + -3 * (syn_students$SleepHours - 7.5)^2 +\n     rnorm(n_students, mean = 0, sd = 8), 1 )\n\nhead(syn_students)\n\n  studentID  Age Gender SleepHours StudyHours ExamScore\n1         1 18.3 Female        6.3       13.8      95.8\n2         2 19.3 Female        5.8       10.7      74.5\n3         3 24.7 Female        7.2        5.7      78.7\n4         4 20.2 Female        7.0        4.4      70.2\n5         5 20.4   Male        4.9       18.3      74.4\n6         6 25.1   Male        7.0        7.3      71.3\n\n#Save as RDS\nsaveRDS(syn_students, file = \"synthetic_students.rds\")\n\n\n\nPlotting\nThe plots explore the relationships between exam scores and the student variables. Boxplots show how exam scores vary by gender, while scatterplots illustrate how exam scores change with study hours, sleep hours, and age. The study hours plot reveals a positive linear trend, the sleep hours plot shows a curved relationship with optimal performance around 7–8 hours, and the age plot shows little effect, as expected. These plots confirm that the synthetic data reflect the relationships built into the dataset.\n\n#Boxplot of Exam Score by Gender\nplot1 &lt;- ggplot(syn_students, aes(x = Gender, y = ExamScore)) +\n  geom_boxplot(fill = \"lightgreen\") +\n  labs(\n    x = \"Gender\",\n    y = \"Exam Score\",\n    title = \"Exam Score by Gender\"\n  ) +\n  theme_bw()\n\n#Scatterplot: Study Hours vs Exam Score\nplot2 &lt;- ggplot(syn_students, aes(x = StudyHours, y = ExamScore)) +\n  geom_point(alpha = 0.5, color = \"darkblue\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(\n    x = \"Study Hours\",\n    y = \"Exam Score\",\n    title = \"Relationship Between Study Hours and Exam Score\"\n  ) +\n  theme_bw()\n\n#Scatterplot: Sleep Hours vs Exam Score \nplot3 &lt;- ggplot(syn_students, aes(x = SleepHours, y = ExamScore)) +\n  geom_point(alpha = 0.5, color = \"darkorange\") +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    x = \"Sleep Hours\",\n    y = \"Exam Score\",\n    title = \"Relationship Between Sleep Hours and Exam Score\"\n  ) +\n  theme_bw()\n\n#Scatterplot: Age vs Exam Score\nplot4 &lt;- ggplot(syn_students, aes(x = Age, y = ExamScore)) +\n  geom_point(alpha = 0.5, color = \"purple\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(\n    x = \"Age\",\n    y = \"Exam Score\",\n    title = \"Relationship Between Age and Exam Score\"\n  ) +\n  theme_bw()\n\nplots &lt;- list(plot1, plot2, plot3, plot4)\nfilenames &lt;- c(\"gender_vs_score.png\", \"study_vs_score.png\", \"sleep_vs_score.png\", \"age_vs_score.png\")\n\nfor(i in seq_along(plots)) {\n  ggsave(\n    filename = file.path(\"figures\", filenames[i]),\n    plot = plots[[i]],\n    width = 6,\n    height = 4,\n    dpi = 300\n  )\n}\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\nlm_es &lt;- lm(ExamScore ~ SleepHours + StudyHours, data = syn_students)\nsummary(lm_es)\n\n\nCall:\nlm(formula = ExamScore ~ SleepHours + StudyHours, data = syn_students)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.801  -5.914   0.270   5.829  26.225 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  21.2426     4.0735   5.215 3.89e-07 ***\nSleepHours    3.6305     0.5311   6.835 6.36e-11 ***\nStudyHours    2.4002     0.1490  16.112  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.788 on 247 degrees of freedom\nMultiple R-squared:  0.5499,    Adjusted R-squared:  0.5463 \nF-statistic: 150.9 on 2 and 247 DF,  p-value: &lt; 2.2e-16\n\nglm_es &lt;- glm(ExamScore ~ SleepHours + StudyHours, data = syn_students, family = gaussian())\nsummary(glm_es)\n\n\nCall:\nglm(formula = ExamScore ~ SleepHours + StudyHours, family = gaussian(), \n    data = syn_students)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  21.2426     4.0735   5.215 3.89e-07 ***\nSleepHours    3.6305     0.5311   6.835 6.36e-11 ***\nStudyHours    2.4002     0.1490  16.112  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 95.80345)\n\n    Null deviance: 52574  on 249  degrees of freedom\nResidual deviance: 23663  on 247  degrees of freedom\nAIC: 1855\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Hello! My name is Riley Herber, and I am a Bioinformatics Master’s student at the University of Georgia. I graduated from UGA with a BS in Biochemistry and Molecular Biology and enrolled into the Double Dawgs program.\n\n\nWhile I am not currently in a research lab, I have past experience working under other Bioinformatics PhD students. I have experience with other programming languages such as:\n\nMATLAB\nC++\nPython\n\nI have basic data analysis and modeling experience with these languages.\n\n\n\nI will be taking BIOS7010 alongside this course, but have taken Statistical Inference for the Life Sciences (BINF 8441) in the past, which introduced statistical topics such as probability, maximum likelihood, Bayesian inference, linear regression, etc.\n\n\n\nI hope to learn how to adequately design and use effective data analysis workflows. I want to gain hands-on experience with a variety of analytical methods that will help me approach future research questions and real-world problems with confidence. I am currently unfamiliar with Positron and Quarto, so I am especially excited to expand my technical skill set by learning these tools, along with others we will explore throughout the semester.\n\n\n\nClimate Spiral Visualization\nThis website provides a cool example of how data analysis and visualization is important, while being very visually engaging and impactful. This animation shows how global temperatures have changed over time, using a spiral that expands outward as the Earth warms. It’s a great example of how data analysis can be turned into a visual story and then communicated to the audience."
  },
  {
    "objectID": "aboutme.html#background",
    "href": "aboutme.html#background",
    "title": "About me",
    "section": "",
    "text": "While I am not currently in a research lab, I have past experience working under other Bioinformatics PhD students. I have experience with other programming languages such as:\n\nMATLAB\nC++\nPython\n\nI have basic data analysis and modeling experience with these languages."
  },
  {
    "objectID": "aboutme.html#statistical-background",
    "href": "aboutme.html#statistical-background",
    "title": "About me",
    "section": "",
    "text": "I will be taking BIOS7010 alongside this course, but have taken Statistical Inference for the Life Sciences (BINF 8441) in the past, which introduced statistical topics such as probability, maximum likelihood, Bayesian inference, linear regression, etc."
  },
  {
    "objectID": "aboutme.html#hopes-for-this-class",
    "href": "aboutme.html#hopes-for-this-class",
    "title": "About me",
    "section": "",
    "text": "I hope to learn how to adequately design and use effective data analysis workflows. I want to gain hands-on experience with a variety of analytical methods that will help me approach future research questions and real-world problems with confidence. I am currently unfamiliar with Positron and Quarto, so I am especially excited to expand my technical skill set by learning these tools, along with others we will explore throughout the semester."
  },
  {
    "objectID": "aboutme.html#link",
    "href": "aboutme.html#link",
    "title": "About me",
    "section": "",
    "text": "Climate Spiral Visualization\nThis website provides a cool example of how data analysis and visualization is important, while being very visually engaging and impactful. This animation shows how global temperatures have changed over time, using a spiral that expands outward as the Earth warms. It’s a great example of how data analysis can be turned into a visual story and then communicated to the audience."
  }
]